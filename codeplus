"""
Azure Document Intelligence Wrapper for Dynamic Documents
Supports flexible extraction from any document type with configurable field mappings
"""

from azure.ai.formrecognizer import DocumentAnalysisClient
from azure.core.credentials import AzureKeyCredential
from typing import Dict, List, Optional, Union, Any
import json
import re
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DynamicDocumentExtractor:
    """
    Dynamic document extractor that can handle any document type
    with configurable field extraction patterns
    """
    
    def __init__(self, endpoint: str, api_key: str):
        """Initialize the Document Intelligence client"""
        self.endpoint = endpoint
        self.credential = AzureKeyCredential(api_key)
        self.client = DocumentAnalysisClient(
            endpoint=self.endpoint,
            credential=self.credential
        )
        logger.info("Dynamic Document Extractor initialized")
        
        # Predefined patterns for common document types
        self.document_patterns = {
            "PAN": {
                "fields": {
                    "pan_number": {
                        "patterns": [r"[A-Z]{5}[0-9]{4}[A-Z]{1}"],
                        "keywords": ["permanent account number", "pan", "income tax"],
                        "required": True
                    },
                    "name": {
                        "patterns": [r"Name\s*[:\-]?\s*([A-Z\s]+)", r"नाम\s*[:\-]?\s*([A-Z\s]+)"],
                        "keywords": ["name", "नाम"],
                        "required": True
                    },
                    "father_name": {
                        "patterns": [r"Father['\s]*s?\s*Name\s*[:\-]?\s*([A-Z\s]+)", r"पिता का नाम\s*[:\-]?\s*([A-Z\s]+)"],
                        "keywords": ["father", "पिता"],
                        "required": True
                    },
                    "date_of_birth": {
                        "patterns": [
                            r"(\d{2}[/-]\d{2}[/-]\d{4})",
                            r"(\d{2}\s+\w+\s+\d{4})",
                            r"DOB\s*[:\-]?\s*(\d{2}[/-]\d{2}[/-]\d{4})"
                        ],
                        "keywords": ["date of birth", "dob", "birth", "जन्म"],
                        "required": True
                    }
                },
                "model_id": "prebuilt-idDocument"
            },
            "AADHAAR": {
                "fields": {
                    "aadhaar_number": {
                        "patterns": [r"\d{4}\s+\d{4}\s+\d{4}", r"\d{12}"],
                        "keywords": ["aadhaar", "आधार"],
                        "required": True
                    },
                    "name": {
                        "patterns": [r"Name\s*[:\-]?\s*([A-Z\s]+)", r"नाम\s*[:\-]?\s*([A-Z\s]+)"],
                        "keywords": ["name", "नाम"],
                        "required": True
                    },
                    "date_of_birth": {
                        "patterns": [r"DOB\s*[:\-]?\s*(\d{2}[/-]\d{2}[/-]\d{4})", r"(\d{2}[/-]\d{2}[/-]\d{4})"],
                        "keywords": ["dob", "birth", "जन्म"],
                        "required": True
                    },
                    "gender": {
                        "patterns": [r"Gender\s*[:\-]?\s*(Male|Female|Other)", r"लिंग\s*[:\-]?\s*(पुरुष|महिला)"],
                        "keywords": ["gender", "sex", "लिंग"],
                        "required": False
                    }
                },
                "model_id": "prebuilt-idDocument"
            },
            "PASSPORT": {
                "fields": {
                    "passport_number": {
                        "patterns": [r"[A-Z]\d{7}"],
                        "keywords": ["passport", "passport no"],
                        "required": True
                    },
                    "name": {
                        "patterns": [r"Name\s*[:\-]?\s*([A-Z\s]+)"],
                        "keywords": ["name", "surname"],
                        "required": True
                    },
                    "date_of_birth": {
                        "patterns": [r"(\d{2}[/-]\d{2}[/-]\d{4})"],
                        "keywords": ["date of birth", "dob"],
                        "required": True
                    },
                    "nationality": {
                        "patterns": [r"Nationality\s*[:\-]?\s*([A-Z]+)"],
                        "keywords": ["nationality"],
                        "required": False
                    }
                },
                "model_id": "prebuilt-idDocument"
            },
            "DRIVING_LICENSE": {
                "fields": {
                    "license_number": {
                        "patterns": [r"[A-Z]{2}\d{2}\s?\d{11}"],
                        "keywords": ["dl", "license number", "driving license"],
                        "required": True
                    },
                    "name": {
                        "patterns": [r"Name\s*[:\-]?\s*([A-Z\s]+)"],
                        "keywords": ["name"],
                        "required": True
                    },
                    "date_of_birth": {
                        "patterns": [r"DOB\s*[:\-]?\s*(\d{2}[/-]\d{2}[/-]\d{4})"],
                        "keywords": ["dob", "birth"],
                        "required": True
                    }
                },
                "model_id": "prebuilt-idDocument"
            }
        }
    
    def extract_from_document(
        self,
        document_path: Optional[str] = None,
        document_url: Optional[str] = None,
        document_type: Optional[str] = None,
        custom_fields: Optional[Dict[str, Any]] = None,
        model_id: str = "prebuilt-document",
        extract_all: bool = False
    ) -> Dict[str, Any]:
        """
        Extract data from dynamic documents
        
        Args:
            document_path: Local path to document
            document_url: URL to document
            document_type: Type of document (PAN, AADHAAR, PASSPORT, etc.)
                          If None, will attempt auto-detection
            custom_fields: Custom field definitions for extraction
                          Format: {"field_name": {"patterns": [...], "keywords": [...]}}
            model_id: Azure model to use
            extract_all: If True, extract all content in addition to specific fields
        
        Returns:
            Dictionary with extracted fields and metadata
        """
        try:
            # Analyze document
            if document_url:
                logger.info(f"Analyzing document from URL")
                poller = self.client.begin_analyze_document_from_url(
                    model_id=model_id,
                    document_url=document_url
                )
            else:
                logger.info(f"Analyzing document from file: {document_path}")
                with open(document_path, "rb") as document:
                    poller = self.client.begin_analyze_document(
                        model_id=model_id,
                        document=document
                    )
            
            result = poller.result()
            logger.info("Document analysis completed")
            
            # Extract full content
            full_content = result.content
            
            # Auto-detect document type if not provided
            if not document_type and not custom_fields:
                document_type = self._auto_detect_document_type(full_content)
                logger.info(f"Auto-detected document type: {document_type}")
            
            # Get field definitions
            if document_type and document_type in self.document_patterns:
                field_definitions = self.document_patterns[document_type]["fields"]
                detected_model = self.document_patterns[document_type].get("model_id", model_id)
                logger.info(f"Using predefined pattern for {document_type}")
            elif custom_fields:
                field_definitions = custom_fields
                detected_model = model_id
                logger.info("Using custom field definitions")
            else:
                field_definitions = {}
                detected_model = model_id
                logger.warning("No field definitions found, extracting all content")
            
            # Extract specific fields
            extracted_data = {
                "document_type": document_type or "UNKNOWN",
                "extraction_timestamp": "",
                "confidence_score": 0.0,
                "extracted_fields": {},
                "validation_status": {},
                "raw_content": full_content if extract_all else None,
                "metadata": {
                    "total_pages": len(result.pages),
                    "model_used": detected_model
                }
            }
            
            # Process each field
            total_confidence = 0
            field_count = 0
            
            for field_name, field_config in field_definitions.items():
                field_result = self._extract_field(
                    full_content,
                    result,
                    field_name,
                    field_config
                )
                
                extracted_data["extracted_fields"][field_name] = field_result["value"]
                extracted_data["validation_status"][field_name] = {
                    "found": field_result["found"],
                    "confidence": field_result["confidence"],
                    "method": field_result["method"],
                    "required": field_config.get("required", False)
                }
                
                if field_result["found"]:
                    total_confidence += field_result["confidence"]
                    field_count += 1
            
            # Calculate overall confidence
            if field_count > 0:
                extracted_data["confidence_score"] = total_confidence / field_count
            
            # Validate extraction
            extracted_data["is_valid"] = self._validate_extraction(
                extracted_data["validation_status"]
            )
            
            return extracted_data
        
        except Exception as e:
            logger.error(f"Error extracting from document: {str(e)}")
            raise
    
    def _extract_field(
        self,
        content: str,
        result,
        field_name: str,
        field_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Extract a specific field using patterns and keywords"""
        patterns = field_config.get("patterns", [])
        keywords = field_config.get("keywords", [])
        
        field_result = {
            "value": None,
            "found": False,
            "confidence": 0.0,
            "method": None
        }
        
        # Method 1: Try regex patterns
        for pattern in patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                # Get the first match (or captured group if exists)
                match = matches[0]
                if isinstance(match, tuple):
                    match = match[0]
                
                field_result["value"] = match.strip()
                field_result["found"] = True
                field_result["confidence"] = 0.9
                field_result["method"] = "regex_pattern"
                logger.info(f"Field '{field_name}' found using pattern: {pattern}")
                return field_result
        
        # Method 2: Try keyword-based extraction
        for keyword in keywords:
            # Look for keyword followed by value
            pattern = rf"{keyword}\s*[:\-]?\s*([^\n]+)"
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                field_result["value"] = matches[0].strip()
                field_result["found"] = True
                field_result["confidence"] = 0.75
                field_result["method"] = "keyword_match"
                logger.info(f"Field '{field_name}' found using keyword: {keyword}")
                return field_result
        
        # Method 3: Try Azure's key-value pairs
        if hasattr(result, 'key_value_pairs'):
            for kv in result.key_value_pairs:
                if kv.key and kv.value:
                    key_text = kv.key.content.lower()
                    if any(keyword.lower() in key_text for keyword in keywords):
                        field_result["value"] = kv.value.content.strip()
                        field_result["found"] = True
                        field_result["confidence"] = kv.confidence
                        field_result["method"] = "azure_kv_pair"
                        logger.info(f"Field '{field_name}' found in Azure KV pairs")
                        return field_result
        
        # Method 4: Try Azure's document fields
        if hasattr(result, 'documents'):
            for doc in result.documents:
                if hasattr(doc, 'fields'):
                    for azure_field_name, azure_field_value in doc.fields.items():
                        if any(keyword.lower() in azure_field_name.lower() for keyword in keywords):
                            if hasattr(azure_field_value, 'content'):
                                field_result["value"] = azure_field_value.content.strip()
                            elif hasattr(azure_field_value, 'value'):
                                field_result["value"] = str(azure_field_value.value)
                            
                            if field_result["value"]:
                                field_result["found"] = True
                                field_result["confidence"] = azure_field_value.confidence if hasattr(azure_field_value, 'confidence') else 0.8
                                field_result["method"] = "azure_document_field"
                                logger.info(f"Field '{field_name}' found in Azure document fields")
                                return field_result
        
        logger.warning(f"Field '{field_name}' not found")
        return field_result
    
    def _auto_detect_document_type(self, content: str) -> Optional[str]:
        """Auto-detect document type based on content"""
        content_lower = content.lower()
        
        # Check for PAN card indicators
        pan_indicators = ["permanent account number", "income tax department", "pan"]
        if any(indicator in content_lower for indicator in pan_indicators):
            if re.search(r"[A-Z]{5}[0-9]{4}[A-Z]{1}", content):
                return "PAN"
        
        # Check for Aadhaar indicators
        aadhaar_indicators = ["aadhaar", "आधार", "unique identification"]
        if any(indicator in content_lower for indicator in aadhaar_indicators):
            if re.search(r"\d{4}\s+\d{4}\s+\d{4}", content):
                return "AADHAAR"
        
        # Check for Passport indicators
        passport_indicators = ["passport", "republic of india"]
        if any(indicator in content_lower for indicator in passport_indicators):
            if re.search(r"[A-Z]\d{7}", content):
                return "PASSPORT"
        
        # Check for Driving License indicators
        dl_indicators = ["driving licence", "driving license", "transport"]
        if any(indicator in content_lower for indicator in dl_indicators):
            return "DRIVING_LICENSE"
        
        return None
    
    def _validate_extraction(self, validation_status: Dict[str, Any]) -> bool:
        """Validate that all required fields were extracted"""
        for field_name, status in validation_status.items():
            if status["required"] and not status["found"]:
                logger.warning(f"Required field '{field_name}' not found")
                return False
        return True
    
    def add_custom_document_type(
        self,
        document_type: str,
        fields: Dict[str, Any],
        model_id: str = "prebuilt-document"
    ):
        """
        Add a custom document type configuration
        
        Args:
            document_type: Name of the document type
            fields: Field definitions
            model_id: Azure model to use
        """
        self.document_patterns[document_type] = {
            "fields": fields,
            "model_id": model_id
        }
        logger.info(f"Added custom document type: {document_type}")
    
    def save_result(self, result: Dict[str, Any], output_path: str):
        """Save extraction result to JSON file"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, indent=2, ensure_ascii=False)
            logger.info(f"Result saved to {output_path}")
        except Exception as e:
            logger.error(f"Error saving result: {str(e)}")
            raise


# Test runner for PAN card
if __name__ == "__main__":
    # Configuration
    ENDPOINT = "https://your-resource-name.cognitiveservices.azure.com/"
    API_KEY = "your-api-key-here"
    
    # Initialize extractor
    extractor = DynamicDocumentExtractor(
        endpoint=ENDPOINT,
        api_key=API_KEY
    )
    
    print("=" * 70)
    print("PAN CARD EXTRACTION TEST")
    print("=" * 70)
    
    # Test Case 1: Extract from PAN card (auto-detect)
    print("\nTest 1: Auto-detection and extraction from PAN card")
    try:
        result = extractor.extract_from_document(
            document_path="path/to/pan_card.jpg",
            model_id="prebuilt-idDocument"
        )
        
        print(f"\nDocument Type: {result['document_type']}")
        print(f"Validation Status: {'✓ VALID' if result['is_valid'] else '✗ INVALID'}")
        print(f"Overall Confidence: {result['confidence_score']:.2%}")
        print(f"\nExtracted Fields:")
        
        for field_name, field_value in result['extracted_fields'].items():
            status = result['validation_status'][field_name]
            check = "✓" if status['found'] else "✗"
            print(f"  {check} {field_name}: {field_value}")
            print(f"     Confidence: {status['confidence']:.2%} | Method: {status['method']}")
        
        # Save result
        extractor.save_result(result, "pan_extraction_result.json")
        
    except Exception as e:
        print(f"Error: {str(e)}")
    
    # Test Case 2: Extract with explicit document type
    print("\n" + "=" * 70)
    print("\nTest 2: Explicit PAN card extraction")
    try:
        result = extractor.extract_from_document(
            document_path="path/to/pan_card.jpg",
            document_type="PAN",
            model_id="prebuilt-idDocument",
            extract_all=True
        )
        
        print(f"\nPAN Number: {result['extracted_fields'].get('pan_number')}")
        print(f"Name: {result['extracted_fields'].get('name')}")
        print(f"Father's Name: {result['extracted_fields'].get('father_name')}")
        print(f"Date of Birth: {result['extracted_fields'].get('date_of_birth')}")
        
    except Exception as e:
        print(f"Error: {str(e)}")
    
    # Test Case 3: Custom field extraction
    print("\n" + "=" * 70)
    print("\nTest 3: Custom field extraction from PAN")
    
    custom_fields = {
        "pan_number": {
            "patterns": [r"[A-Z]{5}[0-9]{4}[A-Z]{1}"],
            "keywords": ["pan", "permanent account number"],
            "required": True
        },
        "holder_name": {
            "patterns": [r"Name\s*[:\-]?\s*([A-Z\s]+)"],
            "keywords": ["name", "holder"],
            "required": True
        }
    }
    
    try:
        result = extractor.extract_from_document(
            document_path="path/to/pan_card.jpg",
            custom_fields=custom_fields,
            model_id="prebuilt-idDocument"
        )
        
        print(f"\nExtracted with custom fields:")
        for field, value in result['extracted_fields'].items():
            print(f"  {field}: {value}")
        
    except Exception as e:
        print(f"Error: {str(e)}")
    
    # Test Case 4: Add and use custom document type
    print("\n" + "=" * 70)
    print("\nTest 4: Custom document type")
    
    # Add custom Voter ID configuration
    extractor.add_custom_document_type(
        document_type="VOTER_ID",
        fields={
            "epic_number": {
                "patterns": [r"[A-Z]{3}\d{7}"],
                "keywords": ["epic", "electors photo identity card"],
                "required": True
            },
            "name": {
                "patterns": [r"Name\s*[:\-]?\s*([A-Z\s]+)"],
                "keywords": ["name"],
                "required": True
            }
        },
        model_id="prebuilt-idDocument"
    )
    
    print("Custom document type 'VOTER_ID' added successfully")
    
    print("\n" + "=" * 70)
    print("TEST COMPLETED")
    print("=" * 70)
